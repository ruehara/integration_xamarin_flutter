#!/usr/bin/env python3
"""
Script para converter o modelo fine_tuned_model_extended.h5 para TFLite
"""

import os
import numpy as np
from tflite_converter import TFLiteConverter
from data_loader import ThaiIDDataLoader

def load_sample_data():
    """Carrega uma amostra dos dados para dataset representativo"""
    print("Carregando dados de amostra...")
    
    try:
        data_loader = ThaiIDDataLoader("dataset/")
        X, y, classes = data_loader.load_data()
        
        if X is not None and len(X) > 0:
            # Normalizar se necessÃ¡rio
            if X.dtype != np.float32:
                X = X.astype(np.float32)
            if np.max(X) > 1.0:
                X = X / 255.0
            
            print(f"Dados carregados: {X.shape}")
            return X[:20], classes  # Usar apenas 20 amostras para dataset representativo
    except Exception as e:
        print(f"Erro ao carregar dados: {e}")
    
    return None, None

def convert_model():
    """Converte o modelo fine_tuned_model_extended.h5 para TFLite"""
    
    print("=" * 60)
    print("ğŸ”„ CONVERSÃƒO MODELO PARA TENSORFLOW LITE")
    print("=" * 60)
    
    # Caminho do modelo treinado
    model_path = "fine_tuned_model_extended.h5"
    output_path = "thai_id_model_extended.tflite"
    
    # Verificar se o modelo existe
    if not os.path.exists(model_path):
        print(f"âŒ Modelo nÃ£o encontrado: {model_path}")
        return False
    
    print(f"ğŸ“ Modelo de entrada: {model_path}")
    print(f"ğŸ“ Arquivo de saÃ­da: {output_path}")
    
    # Carregar dados de amostra para quantizaÃ§Ã£o
    X_sample, classes = load_sample_data()
    
    # Criar conversor
    converter = TFLiteConverter(model_path=model_path)
    
    if converter.model is None:
        print("âŒ Erro ao carregar modelo")
        return False
    
    # Configurar dataset representativo se dados estÃ£o disponÃ­veis
    representative_dataset = None
    if X_sample is not None:
        representative_dataset = converter.create_representative_dataset(X_sample)
        print("âœ… Dataset representativo criado")
    
    # Converter modelo
    print("\nğŸ”„ Iniciando conversÃ£o...")
    tflite_model = converter.convert_to_tflite(
        quantization=True,
        representative_dataset=representative_dataset,
        optimize_for_size=True
    )
    
    if tflite_model is None:
        print("âŒ Falha na conversÃ£o")
        return False
    
    # Salvar modelo TFLite
    print("\nğŸ’¾ Salvando modelo TFLite...")
    success = converter.save_tflite_model(tflite_model, output_path)
    
    if not success:
        print("âŒ Falha ao salvar modelo")
        return False
    
    # Obter informaÃ§Ãµes do modelo
    print("\nğŸ“Š InformaÃ§Ãµes do modelo TFLite:")
    model_info = converter.get_model_info(output_path)
    
    # Testar modelo TFLite se temos dados
    if X_sample is not None:
        print("\nğŸ§ª Testando modelo TFLite...")
        try:
            predictions = converter.test_tflite_model(output_path, X_sample[:5])
            if predictions:
                print("âœ… Teste do modelo TFLite bem-sucedido!")
        except Exception as e:
            print(f"âš ï¸ Erro no teste: {e}")
    
    # Comparar com modelo original se possÃ­vel
    if X_sample is not None:
        print("\nğŸ” Comparando modelos...")
        try:
            converter.compare_models(converter.model, output_path, X_sample[:5])
        except Exception as e:
            print(f"âš ï¸ Erro na comparaÃ§Ã£o: {e}")
    
    print("\n" + "ğŸ‰" * 20)
    print("âœ… CONVERSÃƒO CONCLUÃDA COM SUCESSO!")
    print(f"âœ… Modelo TFLite salvo: {output_path}")
    print(f"âœ… Tamanho: {model_info['file_size_mb']:.2f} MB")
    print("ğŸ‰" * 20)
    
    return True

if __name__ == "__main__":
    success = convert_model()
    if success:
        print("\nğŸš€ Modelo pronto para uso em produÃ§Ã£o!")
    else:
        print("\nâŒ ConversÃ£o falhou!")
